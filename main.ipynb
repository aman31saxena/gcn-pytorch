{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_TorchGCN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiJQj_1ekhqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "from sklearn import preprocessing\n",
        "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBkQByyIE8QH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_index_file(filename):\n",
        "    index = []\n",
        "    for line in open(filename):\n",
        "        index.append(int(line.strip()))\n",
        "    return index\n",
        "    \n",
        "def normalize_features(mx):\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "def preprocess_adj(adj):\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    rowsum = np.array(adj.sum(1))\n",
        "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
        "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
        "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
        "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG3_7Rgj6k0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(dataset_str):\n",
        "  names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
        "  objects = []\n",
        "  for i in range(len(names)):\n",
        "      with open(\"data/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n",
        "              objects.append(pkl.load(f, encoding='latin1'))\n",
        "  x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
        "  test_idx_reorder = parse_index_file(\"data/ind.{}.test.index\".format(dataset_str))\n",
        "  test_idx_range = np.sort(test_idx_reorder)\n",
        "  features = sp.vstack((allx, tx)).tolil()\n",
        "  features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "  adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
        "  labels = np.vstack((ally, ty))\n",
        "  labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
        "  idx_test = test_idx_range.tolist()\n",
        "  idx_train = range(len(y))\n",
        "  idx_val = range(len(y), len(y)+500)\n",
        "  features = normalize_features(features)\n",
        "  adj = preprocess_adj(adj + sp.eye(adj.shape[0]))\n",
        "  features = torch.FloatTensor(np.array(features.todense()))\n",
        "  labels = torch.LongTensor(np.where(labels)[1])\n",
        "  adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "  idx_train = torch.LongTensor(idx_train)\n",
        "  idx_val = torch.LongTensor(idx_val)\n",
        "  idx_test = torch.LongTensor(idx_test)\n",
        "  return adj, features, labels, idx_train, idx_val, idx_test\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCSAWbbp8E34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=\"pubmed\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZzMB1S6a3Gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adj, features, labels, idx_train, idx_val, idx_test = load_data(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpu0kwsHFJpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GCN_Layer(Module):\n",
        "\n",
        "    def __init__(self, inputs, outputs, bias=True):\n",
        "        super(GCN_Layer, self).__init__()\n",
        "        self.inputs = input\n",
        "        self.outputs = outputs\n",
        "        self.weights = Parameter(torch.FloatTensor(inputs, outputs))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.FloatTensor(outputs))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.initialize_parameters()\n",
        "\n",
        "    def initialize_parameters(self):\n",
        "        sigma = 1/ math.sqrt(self.weights.size(1))\n",
        "        self.weights.data.uniform_(-sigma, sigma)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-sigma, sigma)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        xw= torch.mm(input, self.weights)\n",
        "        output = torch.spmm(adj,xw)\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '\\n Inputs = \\n' + str(self.inputs) + '\\n to \\n' + 'Ouputs = \\n' + str(self.outputs)\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, no_feat, no_hid, no_class, dropout):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.l1 = GCN_Layer(no_feat, no_hid)\n",
        "        self.l2 = GCN_Layer(no_hid, no_class)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        out1 = F.relu(self.l1(input, adj))\n",
        "        in2 = F.dropout(out1, self.dropout, training=self.training)\n",
        "        out2 = self.l2(in2, adj)\n",
        "        output = F.log_softmax(out2, dim=1)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ-K3WBLFM1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "    \n",
        "def train(epoch,early,minm):\n",
        "    t = time.time()\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(features, adj)\n",
        "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
        "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
        "    \n",
        "    if loss_val<minm:\n",
        "      minm=loss_val\n",
        "      early=0\n",
        "    else:\n",
        "      early=early+1\n",
        "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
        "    print('Epoch: {:04d}'.format(epoch+1),\n",
        "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
        "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
        "          'time: {:.4f}s'.format(time.time() - t))\n",
        "    return early,minm\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    output = model(features, adj)\n",
        "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
        "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
        "    print(\"Test set results:\",\n",
        "          \"loss= {:.4f}\".format(loss_test.item()),\n",
        "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3eyywOhFb1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = GCN(no_feat=features.shape[1],no_hid=16,no_class=labels.max().item() + 1,dropout=0.5)\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.05, weight_decay=5e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG95PA3QFdo3",
        "colab_type": "code",
        "outputId": "d5cef55b-b266-46c0-b723-13ffa409dc9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        }
      },
      "source": [
        "t_start = time.time()\n",
        "early=0;\n",
        "minm=1000;\n",
        "for epoch in range(200):\n",
        "    early,minm = train(epoch,early,minm)\n",
        "    if early is 10:\n",
        "      break;\n",
        "print(\"Training Comlete! \\nTotal time elapsed: {:.4f}s\".format(time.time() - t_start))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 1.1122 acc_train: 0.3333 loss_val: 1.0848 acc_val: 0.3880 time: 0.0440s\n",
            "Epoch: 0002 loss_train: 1.0705 acc_train: 0.4500 loss_val: 1.0769 acc_val: 0.4280 time: 0.0378s\n",
            "Epoch: 0003 loss_train: 1.0445 acc_train: 0.5833 loss_val: 1.0770 acc_val: 0.4500 time: 0.0363s\n",
            "Epoch: 0004 loss_train: 1.0177 acc_train: 0.5667 loss_val: 1.0771 acc_val: 0.4160 time: 0.0354s\n",
            "Epoch: 0005 loss_train: 1.0235 acc_train: 0.5167 loss_val: 1.0641 acc_val: 0.4560 time: 0.0354s\n",
            "Epoch: 0006 loss_train: 0.9539 acc_train: 0.6500 loss_val: 1.0286 acc_val: 0.5220 time: 0.0347s\n",
            "Epoch: 0007 loss_train: 0.9209 acc_train: 0.6833 loss_val: 1.0124 acc_val: 0.5360 time: 0.0392s\n",
            "Epoch: 0008 loss_train: 0.8814 acc_train: 0.7167 loss_val: 0.9765 acc_val: 0.6080 time: 0.0382s\n",
            "Epoch: 0009 loss_train: 0.8447 acc_train: 0.7500 loss_val: 0.9586 acc_val: 0.6280 time: 0.0388s\n",
            "Epoch: 0010 loss_train: 0.8230 acc_train: 0.8167 loss_val: 0.9479 acc_val: 0.5960 time: 0.0427s\n",
            "Epoch: 0011 loss_train: 0.7603 acc_train: 0.8500 loss_val: 0.9305 acc_val: 0.6320 time: 0.0405s\n",
            "Epoch: 0012 loss_train: 0.7190 acc_train: 0.8667 loss_val: 0.9008 acc_val: 0.6560 time: 0.0414s\n",
            "Epoch: 0013 loss_train: 0.6926 acc_train: 0.8167 loss_val: 0.8731 acc_val: 0.6720 time: 0.0407s\n",
            "Epoch: 0014 loss_train: 0.6987 acc_train: 0.8500 loss_val: 0.8634 acc_val: 0.6740 time: 0.0451s\n",
            "Epoch: 0015 loss_train: 0.6047 acc_train: 0.8500 loss_val: 0.8305 acc_val: 0.6700 time: 0.0371s\n",
            "Epoch: 0016 loss_train: 0.5840 acc_train: 0.8833 loss_val: 0.8123 acc_val: 0.7040 time: 0.0367s\n",
            "Epoch: 0017 loss_train: 0.5796 acc_train: 0.8500 loss_val: 0.8083 acc_val: 0.6880 time: 0.0352s\n",
            "Epoch: 0018 loss_train: 0.4984 acc_train: 0.9167 loss_val: 0.7963 acc_val: 0.6860 time: 0.0377s\n",
            "Epoch: 0019 loss_train: 0.4788 acc_train: 0.9333 loss_val: 0.7757 acc_val: 0.7060 time: 0.0358s\n",
            "Epoch: 0020 loss_train: 0.4537 acc_train: 0.9500 loss_val: 0.7535 acc_val: 0.7120 time: 0.0354s\n",
            "Epoch: 0021 loss_train: 0.4539 acc_train: 0.9000 loss_val: 0.7587 acc_val: 0.6820 time: 0.0415s\n",
            "Epoch: 0022 loss_train: 0.3700 acc_train: 0.9667 loss_val: 0.7603 acc_val: 0.6900 time: 0.0380s\n",
            "Epoch: 0023 loss_train: 0.4022 acc_train: 0.9500 loss_val: 0.7263 acc_val: 0.7240 time: 0.0354s\n",
            "Epoch: 0024 loss_train: 0.3481 acc_train: 0.9167 loss_val: 0.7166 acc_val: 0.7120 time: 0.0391s\n",
            "Epoch: 0025 loss_train: 0.3022 acc_train: 0.9833 loss_val: 0.7221 acc_val: 0.7080 time: 0.0360s\n",
            "Epoch: 0026 loss_train: 0.3696 acc_train: 0.9500 loss_val: 0.7033 acc_val: 0.7240 time: 0.0351s\n",
            "Epoch: 0027 loss_train: 0.3274 acc_train: 0.9000 loss_val: 0.7061 acc_val: 0.7100 time: 0.0355s\n",
            "Epoch: 0028 loss_train: 0.3589 acc_train: 0.8500 loss_val: 0.6831 acc_val: 0.7320 time: 0.0351s\n",
            "Epoch: 0029 loss_train: 0.2999 acc_train: 0.9500 loss_val: 0.6917 acc_val: 0.7340 time: 0.0363s\n",
            "Epoch: 0030 loss_train: 0.2952 acc_train: 0.9500 loss_val: 0.7038 acc_val: 0.7340 time: 0.0393s\n",
            "Epoch: 0031 loss_train: 0.2536 acc_train: 0.9833 loss_val: 0.6723 acc_val: 0.7420 time: 0.0362s\n",
            "Epoch: 0032 loss_train: 0.2430 acc_train: 0.9667 loss_val: 0.6696 acc_val: 0.7400 time: 0.0378s\n",
            "Epoch: 0033 loss_train: 0.2790 acc_train: 0.9667 loss_val: 0.6800 acc_val: 0.7500 time: 0.0357s\n",
            "Epoch: 0034 loss_train: 0.2589 acc_train: 0.9500 loss_val: 0.6774 acc_val: 0.7200 time: 0.0350s\n",
            "Epoch: 0035 loss_train: 0.2598 acc_train: 0.9500 loss_val: 0.6741 acc_val: 0.7300 time: 0.0362s\n",
            "Epoch: 0036 loss_train: 0.2323 acc_train: 1.0000 loss_val: 0.6429 acc_val: 0.7520 time: 0.0390s\n",
            "Epoch: 0037 loss_train: 0.2400 acc_train: 0.9833 loss_val: 0.6971 acc_val: 0.7180 time: 0.0492s\n",
            "Epoch: 0038 loss_train: 0.2518 acc_train: 0.9500 loss_val: 0.6863 acc_val: 0.7340 time: 0.0356s\n",
            "Epoch: 0039 loss_train: 0.2307 acc_train: 0.9833 loss_val: 0.6553 acc_val: 0.7600 time: 0.0354s\n",
            "Epoch: 0040 loss_train: 0.2144 acc_train: 1.0000 loss_val: 0.6515 acc_val: 0.7660 time: 0.0406s\n",
            "Epoch: 0041 loss_train: 0.2213 acc_train: 0.9333 loss_val: 0.6468 acc_val: 0.7300 time: 0.0385s\n",
            "Epoch: 0042 loss_train: 0.2921 acc_train: 0.9167 loss_val: 0.6494 acc_val: 0.7320 time: 0.0405s\n",
            "Epoch: 0043 loss_train: 0.2142 acc_train: 1.0000 loss_val: 0.6872 acc_val: 0.7340 time: 0.0370s\n",
            "Epoch: 0044 loss_train: 0.2006 acc_train: 0.9833 loss_val: 0.6520 acc_val: 0.7500 time: 0.0354s\n",
            "Epoch: 0045 loss_train: 0.1942 acc_train: 0.9833 loss_val: 0.6905 acc_val: 0.7160 time: 0.0387s\n",
            "Epoch: 0046 loss_train: 0.2095 acc_train: 1.0000 loss_val: 0.6758 acc_val: 0.7380 time: 0.0365s\n",
            "Training Comlete! \n",
            "Total time elapsed: 1.7714s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8RgZFoZFkWA",
        "colab_type": "code",
        "outputId": "b0f72d2f-803c-4045-9f4d-0c7ef928778d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set results: loss= 0.5885 accuracy= 0.7860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tU7pO5QdGH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
